{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from geopy) (1.50)\n",
      "Requirement already satisfied: boto in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.48.0)\n"
     ]
    }
   ],
   "source": [
    "# Installations\n",
    "!pip install gzip\n",
    "!pip install geopy\n",
    "!pip install boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jsonlines code\n",
    "# Based on:\n",
    "import jsonlines\n",
    "import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all relevant folders across all subdirectories\n",
    "dir_name = 'D:\\Dropbox\\Programming\\COVID_Religion_Project\\COVID-19-TweetIDs\\gz_unzip_test'\n",
    "extension = \".gz\"\n",
    "\n",
    "#os.chdir(dir_name) # change directory from working dir to dir with files\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through items in dir\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        print(item)\n",
    "        file_name = os.path.abspath(item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        zip_ref.extractall(dir_name) # extract file to dir\n",
    "        zip_ref.close() # close file\n",
    "        os.remove(file_name) # delete zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @AnneKPIX: @CDC has activated its emergency operations center. \n",
      "They expect more US cases.\n",
      "#coronavirus\n"
     ]
    }
   ],
   "source": [
    "file = 'D:\\Dropbox\\Programming\\COVID_Religion_Project\\COVID-19-TweetIDs\\gz_unzip_test\\coronavirus-tweet-id-2020-01-21-22.jsonl.gz'\n",
    "f = gzip.open(file, 'rb')\n",
    "file_content = f.readlines()\n",
    "f.close()\n",
    "\n",
    "#Create list of dictionaries\n",
    "final_json = [json.loads(line.decode('utf8')) for line in file_content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'D:\\Dropbox\\Programming\\COVID_Religion_Project\\COVID-19-TweetIDs\\gz_unzip_test\\coronavirus-tweet-id-2020-03-08-17.jsonl'\n",
    "json_list =[]\n",
    "with jsonlines.open(link) as f:\n",
    "    for line in f.iter():\n",
    "        try:\n",
    "            del line['entities']\n",
    "        except:\n",
    "            pass            \n",
    "            \n",
    "        try:\n",
    "            del line['retweeted_status']\n",
    "        except:\n",
    "            #since some tweets were never retweeted\n",
    "            pass\n",
    "        #we don't want unnecessary multi-level nesting\n",
    "        del line['user']['entities']        \n",
    "        json_list.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Shape of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contributors': None,\n",
      " 'coordinates': None,\n",
      " 'created_at': 'Sun Mar 08 17:02:34 +0000 2020',\n",
      " 'display_text_range': [0, 140],\n",
      " 'favorite_count': 0,\n",
      " 'favorited': False,\n",
      " 'full_text': 'RT @RinChupeco: Given coronavirus fears, more people should '\n",
      "              'know about the Corrupted Blood bug in World of Warcraft that '\n",
      "              'caused player charâ€¦',\n",
      " 'geo': None,\n",
      " 'id': 1236698840373383200,\n",
      " 'id_str': '1236698840373383168',\n",
      " 'in_reply_to_screen_name': None,\n",
      " 'in_reply_to_status_id': None,\n",
      " 'in_reply_to_status_id_str': None,\n",
      " 'in_reply_to_user_id': None,\n",
      " 'in_reply_to_user_id_str': None,\n",
      " 'is_quote_status': False,\n",
      " 'lang': 'en',\n",
      " 'place': None,\n",
      " 'retweet_count': 8654,\n",
      " 'retweeted': False,\n",
      " 'source': '<a href=\"http://twitter.com/download/iphone\" '\n",
      "           'rel=\"nofollow\">Twitter for iPhone</a>',\n",
      " 'truncated': False,\n",
      " 'user': {'contributors_enabled': False,\n",
      "          'created_at': 'Fri Apr 18 16:15:45 +0000 2008',\n",
      "          'default_profile': False,\n",
      "          'default_profile_image': False,\n",
      "          'description': 'Novelist, Comic Creator and Flash Fictioneer. Once '\n",
      "                         'and Future Bumpkin. Arbiter of Pie. Digital '\n",
      "                         'chicanery at Penguin Random House. KHive. Opinions '\n",
      "                         'are my own.',\n",
      "          'favourites_count': 54905,\n",
      "          'follow_request_sent': False,\n",
      "          'followers_count': 583,\n",
      "          'following': False,\n",
      "          'friends_count': 1783,\n",
      "          'geo_enabled': True,\n",
      "          'has_extended_profile': False,\n",
      "          'id': 14434693,\n",
      "          'id_str': '14434693',\n",
      "          'is_translation_enabled': False,\n",
      "          'is_translator': False,\n",
      "          'lang': None,\n",
      "          'listed_count': 25,\n",
      "          'location': 'Brooklyn',\n",
      "          'name': 'WilliamOwen, True Believer',\n",
      "          'notifications': False,\n",
      "          'profile_background_color': 'DAECF4',\n",
      "          'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme2/bg.gif',\n",
      "          'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme2/bg.gif',\n",
      "          'profile_background_tile': False,\n",
      "          'profile_image_url': 'http://pbs.twimg.com/profile_images/869641803544252416/X1yVVFge_normal.jpg',\n",
      "          'profile_image_url_https': 'https://pbs.twimg.com/profile_images/869641803544252416/X1yVVFge_normal.jpg',\n",
      "          'profile_link_color': '686868',\n",
      "          'profile_sidebar_border_color': '1F98C7',\n",
      "          'profile_sidebar_fill_color': '663B12',\n",
      "          'profile_text_color': '1F98C7',\n",
      "          'profile_use_background_image': True,\n",
      "          'protected': False,\n",
      "          'screen_name': 'William_A_Owen',\n",
      "          'statuses_count': 66915,\n",
      "          'time_zone': None,\n",
      "          'translator_type': 'none',\n",
      "          'url': 'http://t.co/hGOwcLYh',\n",
      "          'utc_offset': None,\n",
      "          'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "test = json_list[3]\n",
    "pprint.pprint(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'lang']\n"
     ]
    }
   ],
   "source": [
    "cols = list(test.keys())\n",
    "cols.remove('user')\n",
    "print(len(cols))\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing json\n",
    "# https://stackoverflow.com/questions/40588852/pandas-read-nested-json\n",
    "from pandas.io.json import json_normalize \n",
    "df_normal = json_normalize(json_list,\n",
    "                           record_path=['user'],\n",
    "                           meta=cols,\n",
    "                           #record_prefix='user_',\n",
    "                           #meta_prefix='tweet_',\n",
    "                           errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_normal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2f3dcf2735dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_normal' is not defined"
     ]
    }
   ],
   "source": [
    "len(df_normal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Tweet Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Some Functions from Last Time to get us started:\n",
    "def get_wordnet_pos(word):\n",
    "\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "def get_lemmas(text):\n",
    "    stop = nltk.corpus.stopwords.words('english') + list(string.punctuation)\n",
    "    tokens = [i for i in nltk.word_tokenize(text.lower()) if i not in stop]\n",
    "    lemmas = [nltk.stem.WordNetLemmatizer().lemmatize(t, get_wordnet_pos(t)) for t in tokens]\n",
    "    return lemmas\n",
    "\n",
    "def get_tokens(text):\n",
    "    # drop punctuation, but keep stopwords for initial word counting\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = [i for i in nltk.word_tokenize(text.lower())]\n",
    "    return tokens\n",
    "\n",
    "def fill_topic_weights(df_row, bow_corpus):\n",
    "    # Fill topic weights for topics in songs\n",
    "    try:\n",
    "        for i in ldamodel[bow_corpus[df_row.name]]:\n",
    "            df_row[str(i[0])] = i[1]\n",
    "    except:\n",
    "        return df_row\n",
    "    return df_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modelling\n",
    "\n",
    "def top_songs_by_topic(ldamodel, corpus, ntop=1):\n",
    "    #Returns empty dictionary\n",
    "    topn_songs_by_topic = {}\n",
    "    for i in range(len(ldamodel.print_topics())):\n",
    "        # For each topic, collect the most representative song(s) (i.e. highest probability containing words belonging to topic):\n",
    "        top = sorted(zip(range(len(corpus)), ldamodel[corpus]), reverse=True, key=lambda x: abs(dict(x[1]).get(i, 0.0)))\n",
    "        topn_songs_by_topic[i] = [j[0] for j in top[:ntop]]\n",
    "        # Print out the topn songs for each topic and return their indices as a dictionary for further analysis:\n",
    "        print(\"Topic \" + str(i))\n",
    "        print(music_df[['title','year','artist']].loc[topn_songs_by_topic[i]])\n",
    "        print(\"*******************************\")\n",
    "    return topn_songs_by_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(json_list)\n",
    "df_eng = df[df['lang']=='en']\n",
    "tweet_text = df_eng['full_text'].apply(get_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [rt, thedailybeast, snl, brutally, roasts, tru...\n",
       "1        [rt, mlipsitch, important, evidence, on, role,...\n",
       "3        [rt, rinchupeco, given, coronavirus, fears, mo...\n",
       "5        [rt, briankarem, why, are, they, lying, to, us...\n",
       "6        [rt, cameronlmitchel, kylegriffin1, the, trump...\n",
       "9        [white, house, continues, to, lie, about, coro...\n",
       "10       [rt, ketengahketepi, maaf, tanya, part, happy,...\n",
       "11       [rt, granttucker, britain, we, survived, the, ...\n",
       "12       [rt, atrupar, the, president, is, golfing, at,...\n",
       "13       [rt, khjesq, coronavirus, got, boomers, stocki...\n",
       "14       [rt, markjacob16, disappointed, in, the, consp...\n",
       "15       [rt, mikepence, as, a, result, of, president, ...\n",
       "16       [rt, anthonydragons, aiiight, that, â€™, s, it, ...\n",
       "19       [rt, mollyjongfast, the, level, of, incompeten...\n",
       "22       [rt, fairyglowmother, important, to, note, tha...\n",
       "25       [surgeongeneral, indeed, you, repeated, this, ...\n",
       "26       [rt, robmose, wow, a, nursing, home, in, seatt...\n",
       "27       [rt, krisssnicolee, 2004, sars, 2008, avian, 2...\n",
       "28       [rt, thekarami, iran, â€™, s, confirmed, corona,...\n",
       "29       [pancrasmalani, alinaka, bubonic, plague, orig...\n",
       "30       [rt, norbertelekes, breaking, africas, first, ...\n",
       "31       [rt, rahanahussain1, bbc, news, coronavirus, u...\n",
       "33       [rt, slugsrool, atatimelikethis, daisybelll, b...\n",
       "35       [rt, roberts45298013, just, got, an, email, fr...\n",
       "36       [rt, anthonydragons, aiiight, that, â€™, s, it, ...\n",
       "37       [rt, mredwards, ive, heard, that, coronavirus,...\n",
       "39       [rt, itsjefftiedrich, holy, fucking, shit, ove...\n",
       "40       [rt, timrunshismouth, quick, survey, raise, yo...\n",
       "41               [hold, a, rallyðŸ¤žðŸ¤žðŸ¤žðŸ¤žðŸ¤ž, httpstco1rgxrfwqhp]\n",
       "42       [pjainmg, dangarrett97, boycotthegemony, qz, t...\n",
       "                               ...                        \n",
       "49438    [rt, drtedros, the, government, amp, the, peop...\n",
       "49442    [rt, atrupar, in, this, clip, trump, 1, denies...\n",
       "49443    [trump, was, only, early, on, one, thing, elim...\n",
       "49444    [rt, samanthariggs, coronavirus, made, flights...\n",
       "49445    [rt, donaldjtrumpjr, read, this, thread, and, ...\n",
       "49446           [totally, incompetent, httpstcosgio88v9dj]\n",
       "49452    [rt, davidcbaker, as, of, now, 435500, slots, ...\n",
       "49453    [drhume655, stelladesantis4, thelocalspain, th...\n",
       "49455    [rt, joycewhitevance, the, president, of, the,...\n",
       "49456    [trump, clearly, and, unequivocally, meets, hi...\n",
       "49457    [rt, zihluzu, babes, wodumo, explain, the, cau...\n",
       "49458    [rt, nntaleb, beware, journalistic, fallacies,...\n",
       "49459    [rt, gothamist, in, hopes, of, containing, the...\n",
       "49460    [rt, thehill, us, marine, contracts, coronavir...\n",
       "49461    [rt, elonmusk, the, coronavirus, panic, is, dumb]\n",
       "49462    [rt, wionews, currently, there, are, 80695, co...\n",
       "49463    [rt, jamesmatesitv, devastating, new, coronavi...\n",
       "49464    [rt, chris1791, cruise, ship, carrying, 3500, ...\n",
       "49466    [rt, trumpwarroom, watch, dr, anthony, fauci, ...\n",
       "49467    [rt, nytimes, coronavirus, updates, â€”dr, antho...\n",
       "49468        [i, actually, hate, this, httpstco0qpigrrdc0]\n",
       "49469    [rt, trumpwarroom, watch, dr, ben, carson, dis...\n",
       "49470    [rt, scottgottliebmd, thread, on, coronavirus,...\n",
       "49471    [prepping, for, the, coronavirus, and, thinkin...\n",
       "49472    [rt, mmpadellan, surgeon, general, jerome, ada...\n",
       "49473    [rt, xdaneelolivaw, quancyclayborne, its, not,...\n",
       "49474    [rt, lrihendry, iheartmindy, raccoons, are, no...\n",
       "49475    [rt, nycjim, new, italy, reports, 133, coronav...\n",
       "49477    [rt, norbertelekes, breaking, italy, reports, ...\n",
       "49479    [rt, abcliz, update, a, spokesperson, for, pri...\n",
       "Name: full_text, Length: 32121, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure religiosity\n",
    "def relig_perc(text):\n",
    "    relig_count = text.count(\"God\") + text.count(\"Jesus\") + text.count(\"church\") + text.count(\"Lord\") + text.count(\"pray\") + text.count(\"faith\")\n",
    "    return relig_count/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "religiosity = tweet_text.apply(relig_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(religiosity.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Geocodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import OpenMapQuest\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "geolocator = OpenMapQuest(api_key='FGtjwBYCTEadGZpAIEkM2ySw5518bS7b') \n",
    "geocoder = RateLimiter(geolocator.geocode, min_delay_seconds=1) \n",
    "fwp_df['location'] = fwp_df['userlocation'].apply(geocoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
