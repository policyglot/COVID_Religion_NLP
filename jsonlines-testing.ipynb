{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting geopy\n",
      "  Using cached geopy-2.0.0-py3-none-any.whl (111 kB)\n",
      "Collecting geographiclib<2,>=1.49\n",
      "  Using cached geographiclib-1.50-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-1.50 geopy-2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: boto\n",
      "Successfully installed boto-2.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Installations\n",
    "#!pip install gzip\n",
    "#!pip install geopy\n",
    "#!pip install boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jsonlines code\n",
    "# Based on:\n",
    "import jsonlines\n",
    "import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "#Visualization of Final Results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "#Allowing for full text visibility\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all relevant folders across all subdirectories\n",
    "dir_name = 'D:\\Dropbox\\Programming\\COVID_Religion_Project\\COVID-19-TweetIDs\\gz_unzip_test'\n",
    "extension = \".gz\"\n",
    "\n",
    "#os.chdir(dir_name) # change directory from working dir to dir with files\n",
    "\n",
    "for item in os.listdir(dir_name): # loop through items in dir\n",
    "    if item.endswith(extension): # check for \".zip\" extension\n",
    "        print(item)\n",
    "        file_name = os.path.abspath(item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        zip_ref.extractall(dir_name) # extract file to dir\n",
    "        zip_ref.close() # close file\n",
    "        os.remove(file_name) # delete zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for later upgrade to deal with gzip files, rather than just jsonl\n",
    "file = 'D:\\Dropbox\\Programming\\COVID_Religion_Project\\COVID-19-TweetIDs\\gz_unzip_test\\coronavirus-tweet-id-2020-01-21-22.jsonl.gz'\n",
    "f = gzip.open(file, 'rb')\n",
    "file_content = f.readlines()\n",
    "f.close()\n",
    "\n",
    "#Create list of dictionaries\n",
    "final_json = [json.loads(line.decode('utf8')) for line in file_content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that are of interest from the JSON Schema\n",
    "keep_cols = ['created_at','favorite_count', 'full_text', 'id_str', 'lang', 'retweet_count', 'user']\n",
    "user_keep_cols = ['created_at', 'followers_count', 'id_str', 'description', 'location', 'verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_jsonlist(link):\n",
    "    \"\"\"\n",
    "    Takes in a compressed json file, returns a list of json dictionary objects\n",
    "    Deletes the entitites and retweeted_status keys in the dictionary whenever present\n",
    "    Also removes the 'entities' subdictionary to limit the depth of nesting to 1\n",
    "    \"\"\"\n",
    "    json_list =[]\n",
    "    with jsonlines.open(link) as f:        \n",
    "        for line in f.iter():\n",
    "            modified_dict = {}\n",
    "            for k, v in line.items():\n",
    "                if k in keep_cols:\n",
    "                    modified_dict[k] = v                    \n",
    "                json_list.append(modified_dict)\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jul_json = jsonl_to_jsonlist(jul_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " try:\n",
    "                del line['entities']\n",
    "            except:\n",
    "                pass            \n",
    "            \n",
    "            try:\n",
    "                del line['retweeted_status']\n",
    "            except:\n",
    "                #since some tweets were never retweeted\n",
    "                pass\n",
    "            #we don't want unnecessary multi-level nesting\n",
    "            for key in line['user'].keys():\n",
    "                if isinstance(line['user'][key], list):\n",
    "                    line['user'][key] = line['user'][key][0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking sample files from the beginning of Corona cases (March) and the present day\n",
    "#These jsonl files were produced from \n",
    "mar_link = 'COVID-19-TweetIDs\\gz_unzip_test\\coronavirus-tweet-id-2020-03-08-17.jsonl'\n",
    "jul_link = 'COVID-19-TweetIDs\\gz_unzip_test\\coronavirus-tweet-id-2020-07-01-05.jsonl'\n",
    "may_link = 'COVID-19-TweetIDs\\gz_unzip_test\\coronavirus-tweet-id-2020-05-01-10.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = [mar_link, may_link, jul_link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Shape of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_json, may_json, jul_json = (jsonl_to_jsonlist(link) for link in all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Wed Jul 01 04:59:56 +0000 2020',\n",
      " 'favorite_count': 1,\n",
      " 'full_text': 'Prehospitalización de pacientes COVID en la atención primaria: '\n",
      "              'La otra cara del colapso en el Hospital San José '\n",
      "              'https://t.co/VTbNGS2NtD',\n",
      " 'id_str': '1278191585474338816',\n",
      " 'lang': 'es',\n",
      " 'retweet_count': 3}\n"
     ]
    }
   ],
   "source": [
    "test = jul_json[90]\n",
    "pprint.pprint(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_json = jsonl_to_jsonlist(mar_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4ac0fd9683c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjul_json\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#The choice of 39 is random, any number within the length of the JSON list will suffice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test = jul_json[1]\n",
    "#The choice of 39 is random, any number within the length of the JSON list will suffice\n",
    "pprint.pprint(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "We need to convert the nested json structure to a flat one. For this to work, we first find what components of the schema will be most useful for subsequent analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'lang']\n"
     ]
    }
   ],
   "source": [
    "cols = list(test.keys())\n",
    "cols.remove('user')\n",
    "print(len(cols))\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-9fa1125e806a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                            \u001b[1;31m#record_prefix='user_',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                            \u001b[1;31m#meta_prefix='tweet_',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                            errors='ignore')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\normalize.py\u001b[0m in \u001b[0;36mjson_normalize\u001b[1;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep)\u001b[0m\n\u001b[0;32m    273\u001b[0m                              'need distinguishing prefix '.format(name=k))\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3115\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3191\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3192\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3397\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3398\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3399\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3401\u001b[0m             \u001b[1;31m# possibly infer to datetimelike\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#normalizing json\n",
    "# https://stackoverflow.com/questions/40588852/pandas-read-nested-json\n",
    "from pandas.io.json import json_normalize \n",
    "df_normal = json_normalize(mar_json,\n",
    "                           record_path=['user'],\n",
    "                           meta=cols,\n",
    "                           #record_prefix='user_',\n",
    "                           #meta_prefix='tweet_',\n",
    "                           errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>screen_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>protected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>followers_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>friends_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>listed_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>created_at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>favourites_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>utc_offset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>time_zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>geo_enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>statuses_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>contributors_enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>is_translator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>is_translation_enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>profile_background_color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>profile_background_image_url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>profile_background_image_url_https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>profile_background_tile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>profile_image_url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>profile_image_url_https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>profile_banner_url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068681</th>\n",
       "      <td>listed_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068682</th>\n",
       "      <td>created_at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068683</th>\n",
       "      <td>favourites_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068684</th>\n",
       "      <td>utc_offset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068685</th>\n",
       "      <td>time_zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068686</th>\n",
       "      <td>geo_enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068687</th>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068688</th>\n",
       "      <td>statuses_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068689</th>\n",
       "      <td>lang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068690</th>\n",
       "      <td>contributors_enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068691</th>\n",
       "      <td>is_translator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068692</th>\n",
       "      <td>is_translation_enabled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068693</th>\n",
       "      <td>profile_background_color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068694</th>\n",
       "      <td>profile_background_image_url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068695</th>\n",
       "      <td>profile_background_image_url_https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068696</th>\n",
       "      <td>profile_background_tile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068697</th>\n",
       "      <td>profile_image_url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068698</th>\n",
       "      <td>profile_image_url_https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068699</th>\n",
       "      <td>profile_link_color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068700</th>\n",
       "      <td>profile_sidebar_border_color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068701</th>\n",
       "      <td>profile_sidebar_fill_color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068702</th>\n",
       "      <td>profile_text_color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068703</th>\n",
       "      <td>profile_use_background_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068704</th>\n",
       "      <td>has_extended_profile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068705</th>\n",
       "      <td>default_profile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068706</th>\n",
       "      <td>default_profile_image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068707</th>\n",
       "      <td>following</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068708</th>\n",
       "      <td>follow_request_sent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068709</th>\n",
       "      <td>notifications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068710</th>\n",
       "      <td>translator_type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2068711 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0\n",
       "0                                        id\n",
       "1                                    id_str\n",
       "2                                      name\n",
       "3                               screen_name\n",
       "4                                  location\n",
       "5                               description\n",
       "6                                       url\n",
       "7                                  entities\n",
       "8                                 protected\n",
       "9                           followers_count\n",
       "10                            friends_count\n",
       "11                             listed_count\n",
       "12                               created_at\n",
       "13                         favourites_count\n",
       "14                               utc_offset\n",
       "15                                time_zone\n",
       "16                              geo_enabled\n",
       "17                                 verified\n",
       "18                           statuses_count\n",
       "19                                     lang\n",
       "20                     contributors_enabled\n",
       "21                            is_translator\n",
       "22                   is_translation_enabled\n",
       "23                 profile_background_color\n",
       "24             profile_background_image_url\n",
       "25       profile_background_image_url_https\n",
       "26                  profile_background_tile\n",
       "27                        profile_image_url\n",
       "28                  profile_image_url_https\n",
       "29                       profile_banner_url\n",
       "...                                     ...\n",
       "2068681                        listed_count\n",
       "2068682                          created_at\n",
       "2068683                    favourites_count\n",
       "2068684                          utc_offset\n",
       "2068685                           time_zone\n",
       "2068686                         geo_enabled\n",
       "2068687                            verified\n",
       "2068688                      statuses_count\n",
       "2068689                                lang\n",
       "2068690                contributors_enabled\n",
       "2068691                       is_translator\n",
       "2068692              is_translation_enabled\n",
       "2068693            profile_background_color\n",
       "2068694        profile_background_image_url\n",
       "2068695  profile_background_image_url_https\n",
       "2068696             profile_background_tile\n",
       "2068697                   profile_image_url\n",
       "2068698             profile_image_url_https\n",
       "2068699                  profile_link_color\n",
       "2068700        profile_sidebar_border_color\n",
       "2068701          profile_sidebar_fill_color\n",
       "2068702                  profile_text_color\n",
       "2068703        profile_use_background_image\n",
       "2068704                has_extended_profile\n",
       "2068705                     default_profile\n",
       "2068706               default_profile_image\n",
       "2068707                           following\n",
       "2068708                 follow_request_sent\n",
       "2068709                       notifications\n",
       "2068710                     translator_type\n",
       "\n",
       "[2068711 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_normal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Tweet Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Some Functions from Last Time to get us started:\n",
    "def get_wordnet_pos(word):\n",
    "\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "def get_lemmas(text):\n",
    "    stop = nltk.corpus.stopwords.words('english') + list(string.punctuation)\n",
    "    tokens = [i for i in nltk.word_tokenize(text.lower()) if i not in stop]\n",
    "    lemmas = [nltk.stem.WordNetLemmatizer().lemmatize(t, get_wordnet_pos(t)) for t in tokens]\n",
    "    return lemmas\n",
    "\n",
    "def get_tokens(text):\n",
    "    # drop punctuation, but keep stopwords for initial word counting\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = [i for i in nltk.word_tokenize(text.lower())]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_tweet_text(json_lst):\n",
    "    df = pd.DataFrame(json_lst)\n",
    "    df_eng = df[df['lang']=='en']\n",
    "    #tweet_text = df_eng['full_text'].apply(get_tokens)\n",
    "    return df_eng['full_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the religious statements\n",
    "may_df = df = pd.DataFrame(may_json)\n",
    "may_df['relig'] = may_df['full_text'].apply(lambda x: relig_perc(x, relative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1219    RT @misskaul: A short thread on death during a lockdown. Anyone affected, Bollywood stars, or your father in law, beloved doctor for much o…                                                                                                      \n",
       "5163    @sukumaranlens @JMehta65 U rush to your father's bedside at night ..stay by his side all night .. he dies in the morning ... Will u rush home to change your clothes... What an idiotic hypocrite u r. Guys like u make me puke. Fckng get a Life.\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may_df[may_df['relig']==True]['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_text = json_to_tweet_text(mar_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jul_text = json_to_tweet_text(jul_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_text = json_to_tweet_text(may_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        RT @net_drifter: Oh so today, MewGulf had gone...\n",
       "1        #うひーメモ\\n投稿時間:2020-05-01 19:16:50\\nCoronavirus ...\n",
       "2        RT @RobynUrback: To thinking, breathing, moder...\n",
       "3            RT @faizwahab: Majikan won't care. Believe me\n",
       "5        RT @DrGJackBrown: • We do not live for Trump's...\n",
       "7        RT @PodSaveAmerica: Trump dismisses coronaviru...\n",
       "11         @GovMurphy We should maintain social distancing\n",
       "12       @StudentU_UK Looking for Full Refund from Airl...\n",
       "13       RT @ak_annanavarro: there’s doctors literally ...\n",
       "14       RT @CGTNOfficial: The first results from human...\n",
       "15       @BristOliver This is an incredible stat, for e...\n",
       "18       RT @RealErinCruz: No, @GavinNewsom ... you are...\n",
       "19       RT @Rpsingh5153P: My sincere and humble greeti...\n",
       "20       My dear best friend died from Covid19. This is...\n",
       "21       RT @dhanyarajendran: In the last few days, the...\n",
       "24       RT @CBSNews: The family of this 4-year-old say...\n",
       "26       RT @EK_Drake: Refreshing to see such an honest...\n",
       "27       RT @NStaikos: The Victorian Liberals’ three po...\n",
       "29       If watching me answer questions is your idea o...\n",
       "30       RT @ndgazette: Pop-up coronavirus testing site...\n",
       "32       #Nottingham #SocialDistancing \\nNotts Police i...\n",
       "33       RT @OpIndia_com: Guntur: Deceased coronavirus ...\n",
       "34       RT @LeslieH24367191: Must be a bioweapon. \\n\\n...\n",
       "36              You feminist idiot https://t.co/T0E5yRe6Jn\n",
       "37       RT @amandajames61: And now for something compl...\n",
       "38       Runs with the foxes and runs with the hounds h...\n",
       "41       RT @AnthemRespect: Now that’s what I’m talking...\n",
       "42       RT @dampy_malhotra: We will distribute one lak...\n",
       "43       RT @aproko_doctor: 15 doctors have been infect...\n",
       "44       RT @communicipalist: Starmer's \"Constructive O...\n",
       "                               ...                        \n",
       "25750    RT @AfricaFactsZone: Congolese Doctor, Dr. Jer...\n",
       "25755    RT @benatipsosmori: NEW high levels of concern...\n",
       "25756    @ThePlacardGuy Or maybe their just following t...\n",
       "25757    RT @RanjeniM: It looks like the March of the w...\n",
       "25759    Ministry of hindsight at work 🤔 State governme...\n",
       "25764    RT @Wumvengo: Ngo harya ntimushaka urukundo rw...\n",
       "25767    @AndyMac84956921 @AsaWinstanley There’s going ...\n",
       "25770    RT @Iyervval: She stays less than 500 meters f...\n",
       "25772    The higher death rate correlates with higher i...\n",
       "25773    RT @ginasue: Singapore is a cautionary tale: p...\n",
       "25774    RT @freep: Michigan coronavirus death toll hit...\n",
       "25776    RT @MobilePunch: COVID-19: Nigeria lacks bed s...\n",
       "25779    23 May\\nMy birthday was supposed to be celebra...\n",
       "25780                @SkySports What? The Coronavirus Cup?\n",
       "25781    RT @nytimes: The Trump administration and majo...\n",
       "25782    RT @OffGuardian0: @_InThisTogether @Beckyalder...\n",
       "25783    RT @amitmalviya: In a letter to the Union Heal...\n",
       "25785    RT @baymath: The utter gall and caucasity to c...\n",
       "25786    With less than 60 hours left for Lockdown 2.0 ...\n",
       "25787    There are some incredible stories from around ...\n",
       "25788    Day 32 of work from home: I thought the 19 in ...\n",
       "25790    @Beany_1 Spanish flu pandemic 1918. Infected a...\n",
       "25791    Spending lockdown eating biscuits, watching de...\n",
       "25792    RT @lobanherida: [ENG] ~STAY HOME COMIC STRIP ...\n",
       "25793    @UPGovt What about the middle class family peo...\n",
       "25794    RT @prettymayonaise: We've been Goin on about ...\n",
       "25796    RT @ABC: More than 50 people who voted in pers...\n",
       "25797    RT @tr4shish: Universities emailing their stud...\n",
       "25798    RT @uppittynegress: Sex workers are the “Canar...\n",
       "25800    RT @DanielNewman: Trump &amp; DeVos teams were...\n",
       "Name: full_text, Length: 14602, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_vocab = pd.read_csv('relatedQueries.csv')\n",
    "relative_words = list(relative_vocab['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the prayer', 'prayer times', 'prayer time', 'catholic prayer', 'healing prayer', 'serenity prayer', 'serenity', 'what is prayer', 'lords prayer', 'morning prayer', 'prayer for healing', 'jesus prayer', 'daily prayer', 'our father prayer', 'our father', 'prayer quotes', 'muslim prayer', 'lord prayer', 'prayer plant', 'the lords prayer', 'islamic prayer', 'hail mary', 'hail mary prayer', 'house of prayer', 'night prayer']\n"
     ]
    }
   ],
   "source": [
    "print(relative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rising_vocab = pd.read_csv('risingQueries.csv')\n",
    "rising_words = list(rising_vocab['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coronavirus prayer', 'prayer for coronavirus', 'national day of prayer 2020', 'ramadan 2020', 'prayer of spiritual communion', 'spiritual communion prayer', 'prayer for spiritual communion', 'lds sacrament prayer', 'the hunters prayer', 'let this be our prayer', 'sacrament prayer', 'national prayer breakfast', 'communion prayer', 'divine mercy chaplet prayer', 'divine mercy prayer', 'morning prayer for him', 'prayer for the world', 'prayer plant care', 'national day of prayer', 'prayer before bed', 'daily prayer us', 'assembly of prayer', 'prayer plant', 'hail holy queen prayer', 'isha prayer times']\n"
     ]
    }
   ],
   "source": [
    "print(rising_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_words.extend(rising_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the prayer', 'prayer times', 'prayer time', 'catholic prayer', 'healing prayer', 'serenity prayer', 'serenity', 'what is prayer', 'lords prayer', 'morning prayer', 'prayer for healing', 'jesus prayer', 'daily prayer', 'our father prayer', 'our father', 'prayer quotes', 'muslim prayer', 'lord prayer', 'prayer plant', 'the lords prayer', 'islamic prayer', 'hail mary', 'hail mary prayer', 'house of prayer', 'night prayer', 'coronavirus prayer', 'prayer for coronavirus', 'national day of prayer 2020', 'ramadan 2020', 'prayer of spiritual communion', 'spiritual communion prayer', 'prayer for spiritual communion', 'lds sacrament prayer', 'the hunters prayer', 'let this be our prayer', 'sacrament prayer', 'national prayer breakfast', 'communion prayer', 'divine mercy chaplet prayer', 'divine mercy prayer', 'morning prayer for him', 'prayer for the world', 'prayer plant care', 'national day of prayer', 'prayer before bed', 'daily prayer us', 'assembly of prayer', 'prayer plant', 'hail holy queen prayer', 'isha prayer times']\n"
     ]
    }
   ],
   "source": [
    "print(relative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure religiosity\n",
    "def relig_perc(text, vocab):\n",
    "    return any([word in text for word in vocab])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mar_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-32e713c82fc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmar_relig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmar_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrelig_perc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelative_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mar_text' is not defined"
     ]
    }
   ],
   "source": [
    "mar_relig = mar_text.apply(lambda x: relig_perc(x, relative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_relig = may_text.apply(lambda x: relig_perc(x, relative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "5        False\n",
      "7        False\n",
      "11       False\n",
      "12       False\n",
      "13       False\n",
      "14       False\n",
      "15       False\n",
      "18       False\n",
      "19       False\n",
      "20       False\n",
      "21       False\n",
      "24       False\n",
      "26       False\n",
      "27       False\n",
      "29       False\n",
      "30       False\n",
      "32       False\n",
      "33       False\n",
      "34       False\n",
      "36       False\n",
      "37       False\n",
      "38       False\n",
      "41       False\n",
      "42       False\n",
      "43       False\n",
      "44       False\n",
      "         ...  \n",
      "25750    False\n",
      "25755    False\n",
      "25756    False\n",
      "25757    False\n",
      "25759    False\n",
      "25764    False\n",
      "25767    False\n",
      "25770    False\n",
      "25772    False\n",
      "25773    False\n",
      "25774    False\n",
      "25776    False\n",
      "25779    False\n",
      "25780    False\n",
      "25781    False\n",
      "25782    False\n",
      "25783    False\n",
      "25785    False\n",
      "25786    False\n",
      "25787    False\n",
      "25788    False\n",
      "25790    False\n",
      "25791    False\n",
      "25792    False\n",
      "25793    False\n",
      "25794    False\n",
      "25796    False\n",
      "25797    False\n",
      "25798    False\n",
      "25800    False\n",
      "Name: full_text, Length: 14602, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(may_relig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013696753869332968\n"
     ]
    }
   ],
   "source": [
    "print(may_relig.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "jul_relig = jul_text.apply(lambda x: relig_perc(x, relative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.942169712836999e-05\n"
     ]
    }
   ],
   "source": [
    "print(jul_relig.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_to_mean_relig(link):\n",
    "    \"\"\"\n",
    "    \n",
    "    Arguments: The location of the original json file\n",
    "    Returns: The percentage of tweets which have at least one of the religion words\n",
    "    \"\"\"\n",
    "    relig_series = json_to_tweet_text(jsonl_to_jsonlist(link)).apply(lambda x: relig_perc(x, relative_words)) \n",
    "    return relig_series.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013696753869332968\n"
     ]
    }
   ],
   "source": [
    "print(jsonl_to_mean_relig(may_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.942169712836999e-05\n"
     ]
    }
   ],
   "source": [
    "print(jsonl_to_mean_relig(jul_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Geocodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import OpenMapQuest\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "geolocator = OpenMapQuest(api_key='FGtjwBYCTEadGZpAIEkM2ySw5518bS7b') \n",
    "geocoder = RateLimiter(geolocator.geocode, min_delay_seconds=1) \n",
    "fwp_df['location'] = fwp_df['userlocation'].apply(geocoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
